from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from app.rag_chain import vectorstore, embedding_model, llm
from langchain.chains import RetrievalQA
from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
import json, re, textwrap, traceback, requests, os
from bs4 import BeautifulSoup
from difflib import SequenceMatcher
from openai import OpenAI

router = APIRouter()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class ChatRequest(BaseModel):
    message: str

class ChatResponse(BaseModel):
    response: str
    followups: list[str] = []

def preprocess(q: str) -> str:
    q = re.sub(r"(\w+í•™ê³¼)\s*êµìˆ˜", r"\1 ì†Œì† êµìˆ˜", q.strip())
    return re.sub(r"\s+", " ", q)

def build_temp_faiss(filtered, embedding_model, batch_size=100):
    vs = None
    for i in range(0, len(filtered), batch_size):
        part = filtered[i:i+batch_size]
        tmp = FAISS.from_texts(
            texts=[d.page_content for d in part],
            embedding=embedding_model,
            metadatas=[d.metadata for d in part]
        )
        if vs is None:
            vs = tmp
        else:
            vs.merge_from(tmp)
    return vs

def hybrid_retriever(query: str, top_k: int = 4):
    keyword = query.split()[0]
    all_docs = list(vectorstore.docstore._dict.values())
    filtered = [d for d in all_docs if keyword in d.page_content]
    if filtered:
        temp_vs = build_temp_faiss(filtered, embedding_model, batch_size=100)
        return temp_vs.as_retriever(search_kwargs={"k": top_k})
    return vectorstore.as_retriever(search_kwargs={"k": top_k})

BLACKLIST_TERMS = [
    "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ëŠ” ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
    "í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ë‚´ìš©ì€ í˜„ì¬ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
    "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™êµ ê³µì‹ ì±„ë„ì— ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
]

def extract_keywords(text: str) -> list[str]:
    return re.findall(r"[ê°€-í£]{2,}", text)

def is_similar(a: str, b: str, threshold: float = 0.6) -> bool:
    return SequenceMatcher(None, a, b).ratio() > threshold

def generate_followups(question: str, docs: list[Document]) -> list[str]:
    summaries = "\n\n".join(
        textwrap.shorten(d.page_content, width=600, placeholder=" ...") for d in docs[:2]
    )
    prompt = f"""
ë‹¹ì‹ ì€ í•œì–‘ëŒ€í•™êµ ì±—ë´‡ì…ë‹ˆë‹¤.

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}

[ì°¸ì¡° ë¬¸ì„œ ìš”ì•½]
{summaries}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì´ì–´ì„œ ê¶ê¸ˆí•´í•  ë§Œí•œ í›„ì† ì§ˆë¬¸ì„ 0~3ê°œ í•œêµ­ì–´ë¡œ ìƒì„±í•˜ì„¸ìš”. 
ë‹¨, ì§ˆë¬¸ì˜ ëŒ€ìƒì´ ë˜ëŠ” í•™ê³¼ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì§ˆë¬¸ì— ê·¸ í•™ê³¼ëª…ì„ í¬í•¨í•˜ì„¸ìš”.

ìƒì„±ëœ ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•  ìˆ˜ ìˆì–´ì•¼ í•˜ë©°, ë¬¸ì„œì— ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì£¼ì œëŠ” í”¼í•˜ì„¸ìš”. 
ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì˜ ë‹µë³€ì´ ìƒì„±ë˜ë©´ ì•ˆë©ë‹ˆë‹¤.: 
- "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ëŠ” ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
- "í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ë‚´ìš©ì€ í˜„ì¬ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
- "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™êµ ê³µì‹ ì±„ë„ì— ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ: ["ì§ˆë¬¸1", "ì§ˆë¬¸2"]
"""
    resp = llm.invoke(prompt)
    try:
        followups = json.loads(resp.content)
        validated = []
        seen = set()
        for q in followups:
            q_clean = q.strip()

            if any(is_similar(q_clean, prev_q) for prev_q in seen):
                continue

            results = vectorstore.similarity_search(q_clean, k=1)
            if not results:
                continue

            content = results[0].page_content
            if any(term in content for term in BLACKLIST_TERMS):
                continue

            follow_terms = extract_keywords(q_clean)
            content_keywords = extract_keywords(content)
            matched = any(
                is_similar(f_term, c_term)
                for f_term in follow_terms
                for c_term in content_keywords
            )
            if matched:
                validated.append(q_clean)
                seen.add(q_clean)
            if len(validated) >= 3:
                break
        return validated
    except Exception as e:
        print("âš ï¸ follow-up JSON íŒŒì‹± ë˜ëŠ” í•„í„° ì‹¤íŒ¨:", e, "\nì›ë¬¸:", resp.content)
        return []

def search_web_tool(query: str) -> str:
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get("https://www.google.com/search", params={"q": query}, headers=headers)
        soup = BeautifulSoup(response.text, "html.parser")
        results = []

        print("ì›¹ì—ì„œ ì°¾ì€ ì •ë³´ì…ë‹ˆë‹¤.") # ì›¹ ë””ë²„ê¹…

        for g in soup.select("div.g")[:3]:
            title = g.select_one("h3")
            link = g.select_one("a")
            if title and link:
                results.append(f"{title.text.strip()} - {link['href']}")
        return "\n".join(results) if results else "ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

@router.post("/chat", response_model=ChatResponse)
def chat(req: ChatRequest):
    try:
        query = preprocess(req.message)
        retriever = hybrid_retriever(query, top_k=4)

        prompt_template = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ í•œì–‘ëŒ€í•™êµ ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì£¼ì–´ì§„ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

ë¬¸ì„œì— ìœ íš¨í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì •ë³´ë§Œ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

ë§Œì•½ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì „í˜€ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ë°˜ë“œì‹œ ì•„ë˜ ì„¸ ë¬¸ì¥ ì¤‘ í•˜ë‚˜ë§Œ ê·¸ëŒ€ë¡œ ë‹µë³€í•˜ì„¸ìš”:
- "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ëŠ” ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
- "í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ë‚´ìš©ì€ í˜„ì¬ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
- "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™êµ ê³µì‹ ì±„ë„ì— ë¬¸ì˜í•´ ì£¼ì„¸ìš”."

ìœ„ ì„¸ ë¬¸ì¥ì€ ë³€ê²½í•˜ê±°ë‚˜ ì¬êµ¬ì„±í•˜ì§€ ë§ˆì„¸ìš”.

ì§ˆë¬¸: {question}
ë¬¸ì„œ ë‚´ìš©:
{summaries}

ë‹µë³€:
""")

        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            chain_type_kwargs={
                "prompt": prompt_template,
                "document_variable_name": "summaries"
            },
            return_source_documents=True
        )

        qa_result = qa_chain({"query": query})
        answer = qa_result.get("result", "ì£„ì†¡í•©ë‹ˆë‹¤. ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sources = qa_result.get("source_documents", [])
        followups = generate_followups(query, sources)

        if answer.strip().strip('"').strip("'") in BLACKLIST_TERMS:
            tools = [
                {
                    "type": "function",
                    "function": {
                        "name": "search_web",
                        "description": "ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "query": {
                                    "type": "string",
                                    "description": "ê²€ìƒ‰í•  ì§ˆë¬¸"
                                }
                            },
                            "required": ["query"]
                        }
                    }
                }
            ]

            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ í•œì–‘ëŒ€í•™êµ ì±—ë´‡ì…ë‹ˆë‹¤."},
                {"role": "user", "content": query}
            ]

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                tools=tools,
                tool_choice={"type": "function", "function": {"name": "search_web"}}
            )

            message = response.choices[0].message

            if message.tool_calls:
                tool_call = message.tool_calls[0]
                tool_args = json.loads(tool_call.function.arguments)
                web_result = search_web_tool(tool_args["query"])

                messages.append(message)

                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": tool_call.function.name, 
                    "content": web_result
                })
                
                messages.append({
                    "role": "system",
                    "content": "ì›¹ì—ì„œ ì°¾ì€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”. ì‚¬ìš©ìê°€ ë§Œì¡±í•  ìˆ˜ ìˆë„ë¡ ìµœì‹  ì •ë³´ë¥¼ ì „ë‹¬í•˜ì„¸ìš”. â€˜ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤â€™ëŠ” í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."
                })

                second_response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=messages,
                    tools=tools,
                    tool_choice="auto"
                )

                answer = second_response.choices[0].message.content.strip()
        
        print("\n" + "=" * 40)
        print(f"ğŸ—£ ì§ˆë¬¸: {query}")
        for i, d in enumerate(sources):
            meta = d.metadata
            print(f"\nâ€” ë¬¸ì„œ {i+1} â€” label:{meta.get('label')} source:{meta.get('source')}")
        print("\nğŸ’¬ ìµœì¢… ì¶œë ¥:", answer)
        print("=" * 40 + "\n")

        return ChatResponse(response=answer, followups=followups)

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))